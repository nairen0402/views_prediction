{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import datetime\n",
    "import time\n",
    "#API_KEY = 'AIzaSyBBjHEU2XTcP1hn9GVEHt_f4I9jMSIFaPs' # nairen\n",
    "#API_KEY = 'AIzaSyDPHaDiN5kPC23gymzo_J497dVmh5lU65E'  # polybuffer\n",
    "# API_KEY = #daniel\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬取影片資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_data(video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part='statistics, snippet',\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    if 'items' not in response or len(response['items']) == 0:\n",
    "        return None  # Return None if no data\n",
    "\n",
    "    item = response['items'][0]\n",
    "    statistics = item['statistics']\n",
    "    snippet = item['snippet']\n",
    "\n",
    "    # Extracting required data\n",
    "    title = snippet['title']\n",
    "    views = int(statistics.get('viewCount', 0))\n",
    "    likes = int(statistics.get('likeCount', 0))\n",
    "    comments = int(statistics.get('commentCount', 0))\n",
    "    publish_date = snippet['publishedAt']\n",
    "    publish_days = (datetime.datetime.now() - datetime.datetime.fromisoformat(publish_date[:-1])).days\n",
    "\n",
    "    return {\n",
    "        'title': title,\n",
    "        'views': views,\n",
    "        'likes': likes,\n",
    "        'comments': comments,\n",
    "        'publish_days': publish_days,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解析video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids_from_channel(channel_id, max_results=500):\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(video_ids) < max_results:\n",
    "        # Fetching at most 50 results at a time\n",
    "        request = youtube.search().list(\n",
    "            part='id',\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Extract video IDs\n",
    "        for item in response['items']:\n",
    "            if item['id']['kind'] == 'youtube#video':\n",
    "                video_ids.append(item['id']['videoId'])\n",
    "\n",
    "        # Check if there's another page of results\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return video_ids[:max_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                                                             批量存取影片資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_video_data(video_ids):\n",
    "    data = []\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        batch_ids = video_ids[i:i + 50]\n",
    "        request = youtube.videos().list(\n",
    "            part='statistics, snippet',\n",
    "            id=','.join(batch_ids)\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            snippet = item['snippet']\n",
    "            statistics = item['statistics']\n",
    "            publish_date = snippet['publishedAt']\n",
    "            publish_days = (datetime.datetime.now() - datetime.datetime.fromisoformat(publish_date[:-1])).days\n",
    "            views = int(statistics.get('viewCount', 0))\n",
    "\n",
    "            # Filter out videos with 0 views\n",
    "            if views > 0:\n",
    "                data.append({\n",
    "                    'video_id': item['id'],  # 添加 video_id\n",
    "                    'title': snippet['title'],\n",
    "                    'views': views,\n",
    "                    'likes': int(statistics.get('likeCount', 0)),\n",
    "                    'comments': int(statistics.get('commentCount', 0)),\n",
    "                    'publish_days': publish_days\n",
    "                })\n",
    "\n",
    "        # 在每次处理一批视频后延时\n",
    "        time.sleep(2.0)  # 延时 2 秒\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set_Number of Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_video_data(channel_id, max_results=500):\n",
    "    video_ids = get_video_ids_from_channel(channel_id, max_results)\n",
    "    video_data = batch_video_data(video_ids)\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訂閱數資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_subscriber_count(channel_id):\n",
    "    request = youtube.channels().list(\n",
    "        part='statistics',\n",
    "        id=channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    if 'items' not in response or len(response['items']) == 0:\n",
    "        return None\n",
    "\n",
    "    return int(response['items'][0]['statistics'].get('subscriberCount', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 由handle來找channel資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.errors import HttpError\n",
    "def get_channel_id_by_handle(handle):\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part='snippet',\n",
    "            forHandle=handle\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        if 'items' in response and len(response['items']) > 0:\n",
    "            return response['items'][0]['id']\n",
    "        print(\"無法找到頻道，請檢查 Handle 是否正確。\")\n",
    "        return None\n",
    "    except HttpError as e:\n",
    "        print(f\"API 錯誤：{e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def batch_main(handles, csv_file='youtube_video_data.csv'):\n",
    "    all_video_data = []\n",
    "\n",
    "    # 使用 tqdm 進度條\n",
    "    for handle in tqdm(handles, desc=\"處理頻道進度\", unit=\"頻道\"):\n",
    "        print(f\"正在處理頻道: {handle}\")\n",
    "        # 獲取頻道 ID\n",
    "        channel_id = get_channel_id_by_handle(handle)\n",
    "        if not channel_id:\n",
    "            print(f\"無法找到頻道: {handle}\")\n",
    "            continue\n",
    "\n",
    "        # 獲取頻道視頻數據\n",
    "        video_data = get_channel_video_data(channel_id)\n",
    "        if not video_data:\n",
    "            print(f\"未能獲取 {handle} 的任何視頻數據。\")\n",
    "            continue\n",
    "\n",
    "        # 獲取訂閱數\n",
    "        subscribers = get_channel_subscriber_count(channel_id)\n",
    "        for item in video_data:\n",
    "            item['subscribers'] = subscribers\n",
    "        # 將數據追加到總數據中\n",
    "        all_video_data.extend(video_data)\n",
    "\n",
    "    # 使用 tqdm 進度條寫入數據\n",
    "    print(\"正在保存數據到 CSV 文件...\")\n",
    "    with tqdm(total=len(all_video_data), desc=\"保存數據進度\", unit=\"影片\") as pbar:\n",
    "        if not os.path.exists(csv_file):\n",
    "            # 如果文件不存在，創建並寫入表頭\n",
    "            df = pd.DataFrame(all_video_data)\n",
    "            df.to_csv(csv_file, index=False, mode='w', header=True)\n",
    "        else:\n",
    "            # 如果文件存在，追加數據（避免重複）\n",
    "            existing_df = pd.read_csv(csv_file)\n",
    "            new_df = pd.DataFrame(all_video_data)\n",
    "            combined_df = pd.concat([existing_df, new_df]).drop_duplicates(subset='video_id')\n",
    "            combined_df.to_csv(csv_file, index=False, mode='w', header=True)\n",
    "\n",
    "        pbar.update(len(all_video_data))\n",
    "\n",
    "    print(\"所有數據已成功保存到 CSV 文件：\")\n",
    "    print(pd.read_csv(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set_Channel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "處理頻道進度: 100%|██████████| 1/1 [00:00<00:00, 10.84頻道/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在處理頻道: @peetagege\n",
      "API 錯誤：<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/channels?part=snippet&forHandle=%40peetagege&key=AIzaSyBBjHEU2XTcP1hn9GVEHt_f4I9jMSIFaPs&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n",
      "無法找到頻道: @peetagege\n",
      "正在保存數據到 CSV 文件...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "保存數據進度: 0影片 [00:00, ?影片/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有數據已成功保存到 CSV 文件：\n",
      "          video_id                                              title   views  \\\n",
      "0      FgLkUspIsL0                       全職獵人405話完整解說：西索本尊現身，旅團黑幫皆有行動  256441   \n",
      "1      Fy_bHNbWdRU                    拳叔講哆啦A夢：哆啦A夢把房子變身無敵列車頭！開著房子去兜風！  154404   \n",
      "2      61fYLew16O8                      臥底名單洩露，庫拉索的選擇，柯南劇場版20 純黑的噩夢解說   77427   \n",
      "3      SHyMV8kt3F0                            獵人解說2:少數服從多數的陷阱，西索的放養計劃  239759   \n",
      "4      Htyr-4aOqe0                        一反常态的基德，解救业火中的向日葵，柯南剧场版19解说   71886   \n",
      "...            ...                                                ...     ...   \n",
      "10631  WeIdAKTHgaQ                        【試吃】一次吃47款？全日本最奇怪洋芋片是？神馬合體！  206383   \n",
      "10632  XwgCkA3bnR4  【超豪華開箱】超過 100,000 元 !!【復仇者聯盟】系列產品 | 鋼鐵人 + 美隊 +...  798320   \n",
      "10633  Zi4NabzBBNs                             【時光機】聽說50％以上觀眾沒看過這部影片！  198216   \n",
      "10634  xjqlJGsHGNI                  【我是羅大佑，看著我！】空運來的扭蛋開箱！我不要金錢了!JOJO!  103560   \n",
      "10635  ad9qkzeCR44                      【手速5公分】Tommy可以冰淇淋嗎！香草珍奶和隱藏口味？  265629   \n",
      "\n",
      "       likes  comments  publish_days  subscribers  \n",
      "0       2960       504            35       261000  \n",
      "1       1217        31          1849       261000  \n",
      "2        653        69           319       261000  \n",
      "3       1263       150          1053       261000  \n",
      "4        557        64           325       261000  \n",
      "...      ...       ...           ...          ...  \n",
      "10631   7740       359          1493      1370000  \n",
      "10632  18837      3123          2368      1370000  \n",
      "10633   9147       457          1440      1370000  \n",
      "10634   4155       174          1118      1370000  \n",
      "10635   9974       358          1636      1370000  \n",
      "\n",
      "[10636 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "handles = ['@peetagege']  #youtube 主頁網址\n",
    "batch_main(handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import json\\nimport time \\nimport os\\nfrom googleapiclient.discovery import build\\n\\nAPI_KEY = \\'AIzaSyAZioI1gbrRVHsB8Dylb96npimTouclBB8\\'\\nyoutube = build(\\'youtube\\', \\'v3\\', developerKey=API_KEY)\\n\\n# 進度儲存檔案\\nPROGRESS_FILE = \\'search_progress.json\\'\\n\\ndef save_progress(handles, next_page_token):\\n    \"\"\"儲存搜尋進度到檔案\"\"\"\\n    progress_data = {\\n        \"handles\": sorted(list(handles)),  # 確保順序且無重複\\n        \"nextPageToken\": next_page_token\\n    }\\n    with open(PROGRESS_FILE, \\'w\\', encoding=\\'utf-8\\') as f:\\n        json.dump(progress_data, f, ensure_ascii=False, indent=4)\\n\\ndef load_progress():\\n    \"\"\"載入搜尋進度\"\"\"\\n    if os.path.exists(PROGRESS_FILE):\\n        with open(PROGRESS_FILE, \\'r\\', encoding=\\'utf-8\\') as f:\\n            progress_data = json.load(f)\\n            return set(progress_data[\"handles\"]), progress_data[\"nextPageToken\"]\\n    return set(), None\\n\\ndef get_handles_from_keyword(keyword, max_results=50):\\n    handles, next_page_token = load_progress()\\n\\n    while len(handles) < max_results:\\n        # 搜尋頻道\\n        search_request = youtube.search().list(\\n            part=\\'snippet\\',\\n            q=keyword,\\n            type=\\'channel\\',\\n            maxResults=50,\\n            pageToken=next_page_token\\n        )\\n        search_response = search_request.execute()\\n\\n        for item in search_response[\\'items\\']:\\n            channel_id = item[\\'snippet\\'][\\'channelId\\']\\n\\n            # 在每次调用频道 API 前加入延时\\n            time.sleep(3.0)  # 延时 1.5 秒\\n\\n            # 獲取頻道資訊以提取 handle\\n            channel_request = youtube.channels().list(\\n                part=\\'snippet\\',\\n                id=channel_id\\n            )\\n            channel_response = channel_request.execute()\\n\\n            for channel in channel_response[\\'items\\']:\\n                custom_url = channel[\\'snippet\\'].get(\\'customUrl\\', None)\\n                title = channel[\\'snippet\\'][\\'title\\']\\n                handle = f\"@{custom_url}\" if custom_url else f\"@{title.replace(\\' \\', \\'\\').replace(\\'-\\', \\'\\')}\"\\n                handles.add(handle)\\n\\n        # 儲存進度\\n        next_page_token = search_response.get(\\'nextPageToken\\')\\n        save_progress(handles, next_page_token)\\n\\n        if not next_page_token:\\n            break\\n\\n        # 在每次分页请求之间延时\\n        time.sleep(3.0)  \\n\\n    return sorted(list(handles))[:max_results]\\n\\n\\n# 搜尋台灣相關的頻道\\nkeyword = \"台灣\"\\nhandles = get_handles_from_keyword(keyword, max_results=10)\\nprint(\"找到的 Handles:\")\\nbatch_main(handles)\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import json\n",
    "import time \n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "API_KEY = 'AIzaSyAZioI1gbrRVHsB8Dylb96npimTouclBB8'\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# 進度儲存檔案\n",
    "PROGRESS_FILE = 'search_progress.json'\n",
    "\n",
    "def save_progress(handles, next_page_token):\n",
    "    \"\"\"儲存搜尋進度到檔案\"\"\"\n",
    "    progress_data = {\n",
    "        \"handles\": sorted(list(handles)),  # 確保順序且無重複\n",
    "        \"nextPageToken\": next_page_token\n",
    "    }\n",
    "    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(progress_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def load_progress():\n",
    "    \"\"\"載入搜尋進度\"\"\"\n",
    "    if os.path.exists(PROGRESS_FILE):\n",
    "        with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:\n",
    "            progress_data = json.load(f)\n",
    "            return set(progress_data[\"handles\"]), progress_data[\"nextPageToken\"]\n",
    "    return set(), None\n",
    "\n",
    "def get_handles_from_keyword(keyword, max_results=50):\n",
    "    handles, next_page_token = load_progress()\n",
    "\n",
    "    while len(handles) < max_results:\n",
    "        # 搜尋頻道\n",
    "        search_request = youtube.search().list(\n",
    "            part='snippet',\n",
    "            q=keyword,\n",
    "            type='channel',\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        search_response = search_request.execute()\n",
    "\n",
    "        for item in search_response['items']:\n",
    "            channel_id = item['snippet']['channelId']\n",
    "\n",
    "            # 在每次调用频道 API 前加入延时\n",
    "            time.sleep(3.0)  # 延时 1.5 秒\n",
    "\n",
    "            # 獲取頻道資訊以提取 handle\n",
    "            channel_request = youtube.channels().list(\n",
    "                part='snippet',\n",
    "                id=channel_id\n",
    "            )\n",
    "            channel_response = channel_request.execute()\n",
    "\n",
    "            for channel in channel_response['items']:\n",
    "                custom_url = channel['snippet'].get('customUrl', None)\n",
    "                title = channel['snippet']['title']\n",
    "                handle = f\"@{custom_url}\" if custom_url else f\"@{title.replace(' ', '').replace('-', '')}\"\n",
    "                handles.add(handle)\n",
    "\n",
    "        # 儲存進度\n",
    "        next_page_token = search_response.get('nextPageToken')\n",
    "        save_progress(handles, next_page_token)\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        # 在每次分页请求之间延时\n",
    "        time.sleep(3.0)  \n",
    "\n",
    "    return sorted(list(handles))[:max_results]\n",
    "\n",
    "\n",
    "# 搜尋台灣相關的頻道\n",
    "keyword = \"台灣\"\n",
    "handles = get_handles_from_keyword(keyword, max_results=10)\n",
    "print(\"找到的 Handles:\")\n",
    "batch_main(handles)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**提取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**建模**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
